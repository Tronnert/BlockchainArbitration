{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, LongType, StructType, StructField, StringType, DoubleType, BooleanType, IntegerType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/22 18:05:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Crypto').getOrCreate()\n",
    "SCHEMA = StructType([\n",
    "    StructField(\"dt\", LongType(), False),\n",
    "    StructField(\"base\", StringType(), False),\n",
    "    StructField(\"quote\", StringType(), False),\n",
    "    StructField(\"baseWithdrawalFee\", DoubleType(), False),\n",
    "    StructField(\"baseWithdrawalFeeType\", StringType(), False),\n",
    "    StructField(\"quoteWithdrawalFee\", DoubleType(), False),\n",
    "    StructField(\"quoteWithdrawalFeeType\", StringType(), False),\n",
    "    StructField(\"exchange\", StringType(), False),\n",
    "    StructField(\"bidPrice\", DoubleType(), False),\n",
    "    StructField(\"bidQty\", DoubleType(), False),\n",
    "    StructField(\"bidFee\", DoubleType(), False),\n",
    "    StructField(\"askPrice\", DoubleType(), False),\n",
    "    StructField(\"askQty\", DoubleType(), False),\n",
    "    StructField(\"askFee\", DoubleType(), False),\n",
    "])\n",
    "df = spark.read.options(delimiter='\\t', ).csv(\"../logs/logs_1743.tsv\", header=False, schema=SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(\"baseWithdrawalFee\").drop(\"baseWithdrawalFeeType\").drop(\"quoteWithdrawalFee\").drop(\"quoteWithdrawalFeeType\")\n",
    "# df[df[\"takerFee\"].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(x):\n",
    "    d = {\"binance\": 1.0, \"poloniex\": 2.0, \"gate\": 3.0, \"huobi\": 4.0, \"kraken\": 5.0, \"bybit\": 6.0, \"bitget\": 7.0}\n",
    "    return d[x]\n",
    "\n",
    "func_id = f.udf(get_id, DoubleType())\n",
    "df = df.withColumn(\"idExchange\", func_id(\"exchange\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(1, 6):\n",
    "#     exch = df[(df[\"idExchange\"] == float(e)) & (df[\"base\"] == \"TRX\") & (df[\"quote\"] == \"USDT\")].collect()\n",
    "#     bid = [e[\"bidPrice\"] for e in exch]\n",
    "#     ask = [e[\"askPrice\"] for e in exch]\n",
    "#     dt = [e[\"dt\"] for e in exch]\n",
    "#     plt.plot(dt, bid, label=f\"{e} bid\")\n",
    "#     plt.plot(dt, ask, label=f\"{e} ask\")\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupBy(['dt', \"base\", \"quote\"])\\\n",
    "         .agg(f.collect_list(f.struct(\"idExchange\", \"bidPrice\", \"bidQty\", \"askPrice\", \"askQty\", \"bidFee\", \"askFee\")).alias(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(rows):\n",
    "    multed = []\n",
    "    for row_bid in rows:\n",
    "        for row_ask in rows:\n",
    "            if row_bid[\"idExchange\"] != row_ask[\"idExchange\"]:\n",
    "                multed.append([row_bid[\"idExchange\"], \n",
    "                               row_ask[\"idExchange\"], \n",
    "                               row_bid[\"bidPrice\"], \n",
    "                               row_bid[\"bidQty\"], \n",
    "                               row_ask[\"askPrice\"], \n",
    "                               row_ask[\"askQty\"],\n",
    "                               row_bid[\"bidFee\"],\n",
    "                               row_ask[\"askFee\"]])\n",
    "    return multed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_mult = f.udf(mult, ArrayType(ArrayType(DoubleType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.withColumn(\"multed\", func_mult(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyspark_len(x):\n",
    "    return len(x)\n",
    "\n",
    "func_len = f.udf(pyspark_len, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.withColumn(\"len\", func_len(\"multed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test[\"len\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.select(test[\"dt\"], test[\"base\"], test[\"quote\"], f.explode(\"multed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.select(test[\"dt\"], test[\"base\"], test[\"quote\"], *[f.col(\"col\")[e] for e in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.withColumnRenamed(\"col[0]\", \"bidExchange\")\\\n",
    "           .withColumnRenamed(\"col[1]\", \"askExchange\")\\\n",
    "           .withColumnRenamed(\"col[2]\", \"bidPrice\")\\\n",
    "           .withColumnRenamed(\"col[3]\", \"bidQty\")\\\n",
    "           .withColumnRenamed(\"col[4]\", \"askPrice\")\\\n",
    "           .withColumnRenamed(\"col[5]\", \"askQty\")\\\n",
    "           .withColumnRenamed(\"col[6]\", \"bidFee\")\\\n",
    "           .withColumnRenamed(\"col[7]\", \"askFee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.withColumn(\"Qty\", f.least(\"bidQty\", \"askQty\"))\\\n",
    "           .withColumn(\"revenue\", (f.col(\"bidPrice\") * (1 - f.col(\"bidFee\")) - f.col(\"askPrice\") / (1 - f.col(\"askFee\"))) * f.col(\"Qty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# test[test[\"revenue\"].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test.groupBy([\"base\", \"quote\", \"bidExchange\", \"askExchange\"]) \\\n",
    "    .agg(f.collect_list(f.struct(\"dt\", \"bidPrice\", \"askPrice\", \"Qty\", \"revenue\")).alias(\"data\"))\n",
    "\n",
    "def calc_avg(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "\n",
    "def calc_len(x):\n",
    "    return len(x) >= 1\n",
    "\n",
    "\n",
    "def test_len(x):\n",
    "    return len(x)\n",
    "\n",
    "\n",
    "def find(rows):\n",
    "    N = 10 ** 8\n",
    "    if len(rows) == 1:\n",
    "        return [N]\n",
    "    arbitrages = []\n",
    "    rows.sort(key=lambda x: x[\"dt\"])\n",
    "    old = rows[0]\n",
    "    dur = 0\n",
    "    for row in rows[1:]:\n",
    "        if row[\"revenue\"] > 0 and old[\"revenue\"] > 0:\n",
    "            dur += row[\"dt\"] - old[\"dt\"]\n",
    "        elif row[\"revenue\"] <= 0 and old[\"revenue\"] > 0:\n",
    "            arbitrages.append(dur + N)\n",
    "            dur = 0\n",
    "        old = row\n",
    "    if row[\"revenue\"] > 0:\n",
    "        arbitrages.append(dur + N)\n",
    "    return arbitrages\n",
    "\n",
    "\n",
    "func = f.udf(find, ArrayType(LongType()))\n",
    "func2 = f.udf(calc_avg, DoubleType())\n",
    "func3 = f.udf(calc_len, BooleanType())\n",
    "func4 = f.udf(test_len, IntegerType())\n",
    "\n",
    "test3 = test3.withColumn(\"arbitrations\", func(\"data\")) \\\n",
    "    .withColumn(\"is_not_empty\", func3(\"arbitrations\")) \\\n",
    "    .withColumn(\"len\", func4(\"arbitrations\"))\n",
    "test3 = test3[test3[\"is_not_empty\"] == True].withColumn(\"avg_arb\", func2(\"arbitrations\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:======>           (1 + 2) / 3][Stage 29:>                 (0 + 0) / 2]\r"
     ]
    }
   ],
   "source": [
    "test3.sort(\"avg_arb\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
